# Gemini API Proxyï¼ˆå¯ç”¨äºGemini-Cliï¼‰
ä¸€ä¸ªè½»é‡çº§çš„ Google Gemini API å…¼å®¹ä»£ç†æœåŠ¡å™¨ï¼Œå…è®¸æ‚¨ä½¿ç”¨ Gemini API æ ¼å¼è°ƒç”¨ OpenAI å…¼å®¹çš„ LLM æœåŠ¡ã€‚

## ğŸ”¥ Gemini CLI å¿«é€Ÿè®¾ç½®

å½“å‰Gemini CLIä¸èƒ½ç®€å•çš„ä½¿ç”¨geminiä¹‹å¤–çš„æ¨¡å‹ï¼Œæ‰€ä»¥åŸºäºæ­¤éœ€æ±‚å¼€å‘äº†ä¸€ä¸ªpythonå·¥å…·ã€‚

**ä½¿ç”¨æ–¹æ³•ï¼š**
1. ä¿®æ”¹ `config.json` å¡«å…¥ Kimi API key
2. å®‰è£…ä¾èµ–ï¼Œè¿è¡Œ `python gemini_proxy.py`
3. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   export GOOGLE_GEMINI_BASE_URL=http://localhost:8000/
   export GEMINI_API_KEY=sk-1234
   ```
4. åœ¨ Gemini CLI ä¸­ä½¿ç”¨ `/auth`ï¼Œé€‰æ‹© "Use Gemini API Key"

> **âš ï¸ é‡è¦è¯´æ˜ï¼šå½“å‰ç‰ˆæœ¬ä»…åœ¨ Moonshot Kimi ä¸Šè¿›è¡Œè¿‡å®Œæ•´æµ‹è¯•å’Œä¼˜åŒ–ã€‚å…¶ä»– OpenAI å…¼å®¹æœåŠ¡éœ€è¦æ‚¨è‡ªè¡Œæµ‹è¯•å’Œè°ƒæ•´ã€‚**

[English Documentation](README.md) | [è‹±æ–‡æ–‡æ¡£](README.md)

## âœ¨ ç‰¹æ€§

- ğŸ”„ **å®Œæ•´ API å…¼å®¹æ€§** - æ”¯æŒæ‰€æœ‰ Gemini API ç«¯ç‚¹
- ğŸ”€ **æ™ºèƒ½æ ¼å¼è½¬æ¢** - Gemini â†” OpenAI æ ¼å¼æ— ç¼è½¬æ¢  
- ğŸŒŠ **æµå¼å“åº”æ”¯æŒ** - å®Œæ•´çš„ Server-Sent Events æµå¼å¤„ç†
- ğŸ› ï¸ **å‡½æ•°è°ƒç”¨æ”¯æŒ** - å·¥å…·è°ƒç”¨çš„åŒå‘è½¬æ¢
- ğŸ—£ï¸ **å¤šè½®å¯¹è¯** - å®Œæ•´çš„å¯¹è¯å†å²å¤„ç†
- ğŸ“Š **æ¨¡å‹æ˜ å°„** - çµæ´»çš„æ¨¡å‹åç§°æ˜ å°„é…ç½®
- ğŸ“ **è¯¦ç»†æ—¥å¿—** - å¯é…ç½®çš„è®¿é—®æ—¥å¿—å’Œè¯¦ç»†è¯·æ±‚æ—¥å¿—
- âš™ï¸ **é…ç½®æ–‡ä»¶** - JSON é…ç½®æ–‡ä»¶ç»Ÿä¸€ç®¡ç†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- ä¾èµ–åŒ…ï¼š`fastapi`ã€`uvicorn`ã€`openai`

### 2. å®‰è£…ä¾èµ–

```bash
pip install fastapi uvicorn openai
```

### 3. é…ç½®æ–‡ä»¶

åˆ›å»º `config.json` æ–‡ä»¶ï¼š

```json
{
  "openai_api_key": "sk-your-kimi-api-key",
  "openai_base_url": "https://api.moonshot.cn/v1",
  "model_mapping": {
    "gemini-2.5-pro": "kimi-k2-0711-preview",
    "gemini-2.5-flash": "moonshot-v1-auto",
  },
  "default_openai_model": "kimi-k2-0711-preview",
  "server": {
    "host": "0.0.0.0",
    "port": 8000,
    "log_level": "info"
  },
  "logging": {
    "enable_detailed_logs": true,
    "enable_access_logs": true,
    "log_directory": "logs"
  }
}
```

### 4. å¯åŠ¨æœåŠ¡

```bash
python gemini_proxy_for_kimi.py
```

æœåŠ¡å°†åœ¨ `http://0.0.0.0:8000` å¯åŠ¨ã€‚

## ğŸ“– API ä½¿ç”¨

### åŸºæœ¬è¯·æ±‚

```bash
curl -X POST http://localhost:8000/v1beta/models/gemini-2.5-pro:generateContent \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{
      "parts": [{"text": "Hello, how are you?"}]
    }],
    "generationConfig": {
      "temperature": 0.7,
      "maxOutputTokens": 200
    }
  }'
```

### æµå¼è¯·æ±‚

```bash
curl -X POST http://localhost:8000/v1beta/models/gemini-2.5-pro:streamGenerateContent \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{
      "parts": [{"text": "Write a short story"}]
    }]
  }'
```

### Token è®¡æ•°

```bash
curl -X POST http://localhost:8000/v1beta/models/gemini-2.5-pro:countTokens \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{
      "parts": [{"text": "Count tokens for this text"}]
    }]
  }'
```

### å‡½æ•°è°ƒç”¨

```bash
curl -X POST http://localhost:8000/v1beta/models/gemini-2.5-pro:generateContent \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{
      "parts": [{"text": "What is the weather like in Beijing?"}]
    }],
    "tools": [{
      "functionDeclarations": [{
        "name": "get_weather",
        "description": "Get weather information for a city",
        "parameters": {
          "type": "object",
          "properties": {
            "city": {"type": "string", "description": "City name"},
            "date": {"type": "string", "description": "Date in YYYY-MM-DD format"}
          },
          "required": ["city"]
        }
      }]
    }]
  }'
```

## ğŸ”§ é…ç½®è¯´æ˜

### å®Œæ•´é…ç½®æ–‡ä»¶ (config.json)

```json
{
  "openai_api_key": "sk-your-kimi-api-key",
  "openai_base_url": "https://api.moonshot.cn/v1",
  "model_mapping": {
    "gemini-2.5-pro": "kimi-k2-0711-preview",
    "gemini-2.5-flash": "moonshot-v1-auto",
  },
  "default_openai_model": "kimi-k2-0711-preview",
  "server": {
    "host": "0.0.0.0",
    "port": 8000,
    "log_level": "info"
  },
  "logging": {
    "enable_detailed_logs": false,
    "enable_access_logs": true,
    "log_directory": "logs"
  }
}
```

### é…ç½®é¡¹è¯´æ˜

| é…ç½®é¡¹ | è¯´æ˜ | é»˜è®¤å€¼ |
|--------|------|--------|
| `openai_api_key` | OpenAI API å¯†é’¥ | å¿…éœ€ |
| `openai_base_url` | OpenAI API åŸºç¡€ URL | `https://api.openai.com/v1` |
| `model_mapping` | Gemini æ¨¡å‹åˆ° OpenAI æ¨¡å‹çš„æ˜ å°„ | `{}` |
| `default_openai_model` | é»˜è®¤ OpenAI æ¨¡å‹ | `gpt-3.5-turbo` |
| `server.host` | ç›‘å¬åœ°å€ | `0.0.0.0` |
| `server.port` | ç›‘å¬ç«¯å£ | `8000` |
| `server.log_level` | æ—¥å¿—çº§åˆ« | `info` |
| `logging.enable_detailed_logs` | å¯ç”¨è¯¦ç»†è¯·æ±‚æ—¥å¿— | `false` |
| `logging.enable_access_logs` | å¯ç”¨è®¿é—®æ—¥å¿— | `true` |
| `logging.log_directory` | æ—¥å¿—ç›®å½• | `logs` |

## ğŸ“Š æ”¯æŒçš„ LLM æœåŠ¡

### âœ… ç»è¿‡æµ‹è¯•çš„æœåŠ¡

#### Kimi (æœˆä¹‹æš—é¢) - æ¨è
```json
{
  "openai_api_key": "sk-xxx",
  "openai_base_url": "https://api.moonshot.cn/v1",
  "model_mapping": {
    "gemini-2.5-pro": "kimi-k2-0711-preview",
    "gemini-2.5-flash": "kimi-k2-0711-preview"
  }
}
```

### âš ï¸ éœ€è¦è‡ªè¡Œæµ‹è¯•çš„æœåŠ¡

> **æ³¨æ„ï¼šä»¥ä¸‹æœåŠ¡ç†è®ºä¸Šå…¼å®¹ï¼Œä½†éœ€è¦æ‚¨è‡ªè¡Œæµ‹è¯•å’Œè°ƒæ•´ã€‚å¯ä»¥æ‰“å¼€é…ç½®æ–‡ä»¶ä¸­çš„enable_detailed_logsï¼Œä¼šè¾“å‡ºè¯·æ±‚å’Œè¾“å‡ºçš„è¯¦ç»†ä¿¡æ¯ï¼Œç„¶åé’ˆå¯¹æ€§é€‚é…ã€‚

#### OpenAI
```json
{
  "openai_api_key": "sk-xxx",
  "openai_base_url": "https://api.openai.com/v1",
  "model_mapping": {
    "gemini-2.5-pro": "gpt-4o",
    "gemini-2.5-flash": "gpt-4o-mini"
  }
}
```

#### Azure OpenAI
```json
{
  "openai_api_key": "your-azure-key",
  "openai_base_url": "https://your-resource.openai.azure.com/openai/deployments/your-deployment",
  "model_mapping": {
    "gemini-2.5-pro": "gpt-4",
    "gemini-2.5-flash": "gpt-35-turbo"
  }
}
```

#### DeepSeek
```json
{
  "openai_api_key": "sk-xxx", 
  "openai_base_url": "https://api.deepseek.com/v1",
  "model_mapping": {
    "gemini-2.5-pro": "deepseek-chat",
    "gemini-2.5-flash": "deepseek-chat"
  }
}
```

#### æ™ºè°± AI
```json
{
  "openai_api_key": "your-zhipu-key",
  "openai_base_url": "https://open.bigmodel.cn/api/paas/v4",
  "model_mapping": {
    "gemini-2.5-pro": "glm-4",
    "gemini-2.5-flash": "glm-4-flash"
  }
}
```

#### Ollama (æœ¬åœ°éƒ¨ç½²)
```json
{
  "openai_api_key": "ollama",
  "openai_base_url": "http://localhost:11434/v1",
  "model_mapping": {
    "gemini-2.5-pro": "llama3:8b",
    "gemini-2.5-flash": "llama3:8b"
  }
}
```

### ğŸ› ï¸ è‡ªå®šä¹‰å…¶ä»–æœåŠ¡

å¦‚æœæ‚¨éœ€è¦é€‚é…å…¶ä»– OpenAI å…¼å®¹çš„æœåŠ¡ï¼š

1. **Clone é¡¹ç›®**ï¼š`git clone `
2. **ä¿®æ”¹é…ç½®**ï¼šæ›´æ–° `config.json` ä¸­çš„ API ç«¯ç‚¹å’Œæ¨¡å‹æ˜ å°„
3. **æµ‹è¯•åŠŸèƒ½**ï¼šé‡ç‚¹æµ‹è¯•æµå¼å“åº”ã€å‡½æ•°è°ƒç”¨ã€å¤šè½®å¯¹è¯ï¼Œå¯ä»¥æ‰“å¼€é…ç½®æ–‡ä»¶ä¸­çš„enable_detailed_logsï¼Œä¼šè¾“å‡ºè¯·æ±‚å’Œè¾“å‡ºçš„è¯¦ç»†ä¿¡æ¯ï¼Œç„¶åé’ˆå¯¹æ€§é€‚é…ã€‚
4. **ä¼˜åŒ–ä»£ç **ï¼šæ ¹æ®ç›®æ ‡æœåŠ¡çš„ç‰¹æ€§è°ƒæ•´è½¬æ¢é€»è¾‘


## ğŸ“ æ—¥å¿—ç³»ç»Ÿ

### è®¿é—®æ—¥å¿—
ç®€æ´çš„è®¿é—®æ—¥å¿—ï¼Œæ˜¾ç¤ºæ¯ä¸ªè¯·æ±‚çš„åŸºæœ¬ä¿¡æ¯ï¼š
```
ğŸš€ POST /v1beta/models/gemini-2.5-pro:generateContent - 200 - Model: gemini-2.5-pro - ID: abc12345 - 2.341s
ğŸš€ POST /v1beta/models/gemini-2.5-pro:streamGenerateContent - 200 - Model: gemini-2.5-pro(stream) - ID: def67890 - 5.123s
```

### è¯¦ç»†æ—¥å¿—
å®Œæ•´çš„è¯·æ±‚/å“åº”è½¬æ¢è¿‡ç¨‹ï¼ˆå¯é€‰å¼€å¯ï¼‰ï¼š
- `1_GEMINI_REQUEST` - åŸå§‹ Gemini è¯·æ±‚
- `2_OPENAI_REQUEST` - è½¬æ¢åçš„ OpenAI è¯·æ±‚  
- `3_OPENAI_RESPONSE` - OpenAI åŸå§‹å“åº”
- `4_GEMINI_RESPONSE` - æœ€ç»ˆ Gemini å“åº”

## ğŸš€ ç”Ÿäº§éƒ¨ç½²

### ä½¿ç”¨ Gunicorn (æ¨è)

1. å®‰è£… Gunicornï¼š
```bash
pip install gunicorn
```

2. åˆ›å»ºå¯åŠ¨è„šæœ¬ `start.sh`ï¼š
```bash
#!/bin/bash
gunicorn gemini_proxy_for_kimi:app \
  --worker-class uvicorn.workers.UvicornWorker \
  --workers 4 \
  --bind 0.0.0.0:8000 \
  --access-logfile - \
  --error-logfile - \
  --log-level info
```

3. è¿è¡Œï¼š
```bash
chmod +x start.sh
./start.sh
```

### ä½¿ç”¨ systemd æœåŠ¡

åˆ›å»º `/etc/systemd/system/gemini-proxy.service`ï¼š

```ini
[Unit]
Description=Gemini API Proxy
After=network.target

[Service]
Type=exec
User=your-user
Group=your-group
WorkingDirectory=/path/to/your/app
ExecStart=/path/to/your/venv/bin/gunicorn gemini_proxy_for_kimi:app \
  --worker-class uvicorn.workers.UvicornWorker \
  --workers 4 \
  --bind 0.0.0.0:8000
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š
```bash
sudo systemctl daemon-reload
sudo systemctl enable gemini-proxy
sudo systemctl start gemini-proxy
```

### Nginx åå‘ä»£ç†

åˆ›å»º Nginx é…ç½®ï¼š

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # æ”¯æŒæµå¼å“åº”
        proxy_buffering off;
        proxy_cache off;
        
        # å¢åŠ è¶…æ—¶æ—¶é—´
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
}
```

### æ€§èƒ½ä¼˜åŒ–

1. **Worker æ•°é‡**ï¼šæ ¹æ® CPU æ ¸å¿ƒæ•°è®¾ç½®ï¼Œå»ºè®® `2 * CPU_CORES + 1`

2. **å†…å­˜ä¼˜åŒ–**ï¼š
```bash
# é™åˆ¶å†…å­˜ä½¿ç”¨
gunicorn --max-requests 1000 --max-requests-jitter 100 ...
```

3. **è¿æ¥æ± **ï¼šåœ¨é…ç½®ä¸­å¢åŠ è¿æ¥æ± è®¾ç½®

4. **ç¼“å­˜**ï¼šå¯ä»¥æ·»åŠ  Redis ç¼“å­˜å±‚æ¥ç¼“å­˜å“åº”

## ğŸ” ç›‘æ§å’Œç»´æŠ¤

### å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8000/health
```

è¿”å›ï¼š
```json
{"status": "healthy", "service": "gemini-proxy"}
```

### æ—¥å¿—è½®è½¬

ä½¿ç”¨ logrotate ç®¡ç†æ—¥å¿—æ–‡ä»¶ï¼š

```bash
# /etc/logrotate.d/gemini-proxy
/path/to/your/app/logs/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    create 644 your-user your-group
    postrotate
        systemctl reload gemini-proxy
    endscript
}
```

### ç›‘æ§æŒ‡æ ‡

è®¿é—®æ—¥å¿—åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
- è¯·æ±‚æ–¹æ³•å’Œè·¯å¾„
- å“åº”çŠ¶æ€ç 
- ä½¿ç”¨çš„æ¨¡å‹
- è¯·æ±‚ ID
- å“åº”æ—¶é—´

## ğŸ› ï¸ å¼€å‘å’Œè°ƒè¯•

### å¼€å‘æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
# åœ¨ config.json ä¸­è®¾ç½®
{
  "logging": {
    "enable_detailed_logs": true,
    "enable_access_logs": true
  }
}

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python gemini_proxy_for_kimi.py
```

### è°ƒè¯•æŠ€å·§

1. **æŸ¥çœ‹è¯¦ç»†æ—¥å¿—**ï¼šå¯ç”¨ `enable_detailed_logs` æŸ¥çœ‹å®Œæ•´è½¬æ¢è¿‡ç¨‹
2. **æ¨¡å‹æ˜ å°„æµ‹è¯•**ï¼šä½¿ç”¨ä¸åŒçš„ Gemini æ¨¡å‹åæµ‹è¯•æ˜ å°„
3. **æµå¼å“åº”è°ƒè¯•**ï¼šè§‚å¯Ÿ SSE æ•°æ®æµ
4. **å‡½æ•°è°ƒç”¨è°ƒè¯•**ï¼šæ£€æŸ¥å·¥å…·è°ƒç”¨çš„æ ¼å¼è½¬æ¢

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
git clone 
cd gemini-proxy
pip install -r requirements.txt
```

### ä»£ç è§„èŒƒ

- éµå¾ª PEP 8 ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„ç±»å‹æ³¨è§£
- ç¼–å†™æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²
- ç¡®ä¿å‘åå…¼å®¹æ€§

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: æ”¯æŒå“ªäº› Gemini API ç«¯ç‚¹ï¼Ÿ
A: æ”¯æŒ `generateContent`ã€`streamGenerateContent`ã€`countTokens` å’Œ `health` ç«¯ç‚¹ã€‚

### Q: ç›®å‰æ”¯æŒå“ªäº› LLM æœåŠ¡ï¼Ÿ
A: **å½“å‰ä»…åœ¨ Moonshot Kimi ä¸Šè¿›è¡Œè¿‡å®Œæ•´æµ‹è¯•**ã€‚å…¶ä»– OpenAI å…¼å®¹æœåŠ¡ç†è®ºä¸Šå¯ç”¨ï¼Œä½†éœ€è¦æ‚¨è‡ªè¡Œæµ‹è¯•å’Œè°ƒæ•´ã€‚

### Q: å¦‚ä½•é€‚é…å…¶ä»– LLM æœåŠ¡ï¼Ÿ
A: 1) Clone é¡¹ç›®ä»£ç  2) ä¿®æ”¹ `config.json` é…ç½® 3) é‡ç‚¹æµ‹è¯•æµå¼å“åº”ã€å‡½æ•°è°ƒç”¨ç­‰åŠŸèƒ½ 4) æ ¹æ®éœ€è¦è°ƒæ•´ä»£ç é€»è¾‘ 

### Q: ä¸ºä»€ä¹ˆåªæ”¯æŒ Kimiï¼Ÿ
A: å› ä¸ºä¸åŒ LLM æœåŠ¡åœ¨ API ç»†èŠ‚ã€å“åº”æ ¼å¼ã€é”™è¯¯å¤„ç†ç­‰æ–¹é¢å­˜åœ¨å·®å¼‚ï¼Œéœ€è¦é’ˆå¯¹æ€§æµ‹è¯•å’Œä¼˜åŒ–ã€‚ç›®å‰ä¸»è¦ç²¾åŠ›é›†ä¸­åœ¨ Kimi çš„å®Œæ•´é€‚é…ä¸Šã€‚

### Q: æµå¼å“åº”ä¸å·¥ä½œæ€ä¹ˆåŠï¼Ÿ
A: æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ­£ç¡®å¤„ç† `text/event-stream` æ ¼å¼ï¼Œç¡®ä¿ç½‘ç»œç¯å¢ƒæ”¯æŒ SSEã€‚

### Q: å¦‚ä½•å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚ï¼Ÿ
A: å¢åŠ  Gunicorn worker æ•°é‡ï¼Œä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨ï¼Œè€ƒè™‘æ·»åŠ ç¼“å­˜å±‚ã€‚

## ğŸ”— ç›¸å…³é“¾æ¥

- [Google Gemini API æ–‡æ¡£](https://ai.google.dev/gemini-api/docs/text-generation?hl)
- [Moonshot Kimi API æ–‡æ¡£](https://platform.moonshot.cn/docs/introduction)
---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼**